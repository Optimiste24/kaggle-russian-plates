{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3876685-e862-4d78-be5d-4a40af2682f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec27394-1cc2-46bf-9a91-a73dc0538f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's mape: 0.0537468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# 1. Chargement des données\n",
    "data_path = Path(\"C:/Users/Optimiste/Videos/Concours/Prédiction_prix_plaques_russes/data\")\n",
    "train = pd.read_csv(data_path / \"train_2605.csv\")\n",
    "test = pd.read_csv(data_path / \"test_2605.csv\")\n",
    "\n",
    "# 2. Feature Engineering (ajoutez ici vos nouvelles features)\n",
    "def add_features(df):\n",
    "    # Exemple de feature supplémentaire\n",
    "    df['is_military_plate'] = df['letters'].isin(['ААА','ЕКХ','ВОО']).astype(int)\n",
    "    return df\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "# 3. Séparation des features et target\n",
    "features = ['digits', 'letters', 'region_encoded', 'is_gov_plate', \n",
    "            'premium_plate', 'prestige_score', 'is_military_plate']  # Ajoutez toutes vos colonnes features\n",
    "target = 'log_price'\n",
    "\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "\n",
    "# 4. Encodage des variables catégorielles (si nécessaire)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X = X.copy()\n",
    "X['letters_encoded'] = le.fit_transform(X['letters'])\n",
    "\n",
    "\n",
    "# 5. Split train/validation (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Définition des paramètres LightGBM\n",
    "lgbm_params = {\n",
    "    'objective': 'mape',\n",
    "    'boosting_type': 'goss',\n",
    "    'num_leaves': 47,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.8,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "# 7. Custom metric SMAPE\n",
    "def smape_lgbm(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "    return ('SMAPE', smape, False)  # False = plus petit = meilleur\n",
    "\n",
    "# 8. Entraînement du modèle\n",
    "model = LGBMRegressor(**lgbm_params)\n",
    "\n",
    "model.fit(\n",
    "    X_train.drop('letters', axis=1),\n",
    "    y_train,\n",
    "    eval_set=[(X_val.drop('letters', axis=1), y_val)],\n",
    "    eval_metric='mape',\n",
    "    callbacks=[early_stopping(50)]\n",
    ")\n",
    "\n",
    "# 9. Prédiction sur le test set\n",
    "X_test_prepared = test[features].copy()\n",
    "X_test_prepared['letters_encoded'] = le.transform(X_test_prepared['letters'])\n",
    "test_preds = model.predict(X_test_prepared.drop('letters', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1008e4e8-3957-4b56-9e19-d7d08e9c89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.expm1(model.predict(X_test_prepared.drop('letters', axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc28e9-4811-4151-b9a8-c154b820ca23",
   "metadata": {},
   "source": [
    "### Soumission Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42736eea-7f3d-426a-be7f-1577e1560eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"id\"],\n",
    "    \"Price\": test_preds.round()\n",
    "})\n",
    "submission.to_csv(\"submission_lgbm_2605.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc1973-2a70-438b-9fb8-df448fe522fe",
   "metadata": {},
   "source": [
    "### Post-traitement stratégique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e937335-1d4c-4044-b449-9bf18ac377a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f9adf-38ac-42cf-b60c-d719a0ac3121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79029f6e-fac0-4838-8364-b5b996897729",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔗 Phase 2 - Hybridation Intelligente avec Réseau Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1659b60-1a56-444b-bad8-6ed1db0be80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.4-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp39-cp39-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\optimiste\\.conda\\envs\\kaggle_plates\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/375.7 MB 8.3 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 3.4/375.7 MB 8.7 MB/s eta 0:00:43\n",
      "    --------------------------------------- 5.5/375.7 MB 9.1 MB/s eta 0:00:41\n",
      "    --------------------------------------- 7.6/375.7 MB 9.2 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 9.4/375.7 MB 9.5 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 11.5/375.7 MB 9.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 13.4/375.7 MB 9.3 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 15.2/375.7 MB 9.4 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 17.6/375.7 MB 9.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 19.7/375.7 MB 9.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 21.5/375.7 MB 9.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 23.6/375.7 MB 9.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 25.7/375.7 MB 9.5 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 27.5/375.7 MB 9.5 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 29.9/375.7 MB 9.6 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 32.0/375.7 MB 9.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 33.6/375.7 MB 9.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 35.9/375.7 MB 9.6 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 38.0/375.7 MB 9.6 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 40.1/375.7 MB 9.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 41.9/375.7 MB 9.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 44.3/375.7 MB 9.7 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 46.4/375.7 MB 9.7 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 48.5/375.7 MB 9.7 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 50.6/375.7 MB 9.7 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 52.7/375.7 MB 9.8 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 55.1/375.7 MB 9.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 57.4/375.7 MB 9.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 59.8/375.7 MB 9.8 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 61.9/375.7 MB 9.8 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 64.0/375.7 MB 9.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 66.6/375.7 MB 9.9 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 68.7/375.7 MB 9.9 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 70.8/375.7 MB 9.9 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 72.9/375.7 MB 9.9 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 74.7/375.7 MB 9.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 76.8/375.7 MB 9.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 79.2/375.7 MB 9.9 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 81.3/375.7 MB 9.9 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 83.6/375.7 MB 10.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 85.7/375.7 MB 10.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 87.6/375.7 MB 9.9 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 89.7/375.7 MB 9.9 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 91.8/375.7 MB 9.9 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 94.1/375.7 MB 9.9 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 96.5/375.7 MB 10.0 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 98.6/375.7 MB 10.0 MB/s eta 0:00:28\n",
      "   ---------- ---------------------------- 100.9/375.7 MB 10.0 MB/s eta 0:00:28\n",
      "   ---------- ---------------------------- 103.3/375.7 MB 10.0 MB/s eta 0:00:28\n",
      "   ---------- ---------------------------- 105.4/375.7 MB 10.0 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 107.5/375.7 MB 10.0 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 109.8/375.7 MB 10.0 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 112.2/375.7 MB 10.0 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 114.3/375.7 MB 10.1 MB/s eta 0:00:27\n",
      "   ------------ -------------------------- 116.7/375.7 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 118.8/375.7 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 120.6/375.7 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------ -------------------------- 122.9/375.7 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------- ------------------------- 125.3/375.7 MB 10.1 MB/s eta 0:00:25\n",
      "   ------------- ------------------------- 127.9/375.7 MB 10.1 MB/s eta 0:00:25\n",
      "   ------------- ------------------------- 130.3/375.7 MB 10.1 MB/s eta 0:00:25\n",
      "   ------------- ------------------------- 132.4/375.7 MB 10.1 MB/s eta 0:00:25\n",
      "   ------------- ------------------------- 134.5/375.7 MB 10.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------ 136.8/375.7 MB 10.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------ 139.2/375.7 MB 10.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------ 141.0/375.7 MB 10.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------ 143.4/375.7 MB 10.2 MB/s eta 0:00:23\n",
      "   --------------- ----------------------- 145.5/375.7 MB 10.2 MB/s eta 0:00:23\n",
      "   --------------- ----------------------- 148.1/375.7 MB 10.2 MB/s eta 0:00:23\n",
      "   --------------- ----------------------- 150.5/375.7 MB 10.2 MB/s eta 0:00:23\n",
      "   --------------- ----------------------- 152.8/375.7 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------------- ---------------------- 155.2/375.7 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------------- ---------------------- 157.8/375.7 MB 10.2 MB/s eta 0:00:22\n",
      "   ---------------- ---------------------- 160.2/375.7 MB 10.3 MB/s eta 0:00:22\n",
      "   ---------------- ---------------------- 162.3/375.7 MB 10.3 MB/s eta 0:00:21\n",
      "   ----------------- --------------------- 164.6/375.7 MB 10.3 MB/s eta 0:00:21\n",
      "   ----------------- --------------------- 167.0/375.7 MB 10.3 MB/s eta 0:00:21\n",
      "   ----------------- --------------------- 169.3/375.7 MB 10.3 MB/s eta 0:00:21\n",
      "   ----------------- --------------------- 171.7/375.7 MB 10.3 MB/s eta 0:00:20\n",
      "   ------------------ -------------------- 174.3/375.7 MB 10.3 MB/s eta 0:00:20\n",
      "   ------------------ -------------------- 176.7/375.7 MB 10.3 MB/s eta 0:00:20\n",
      "   ------------------ -------------------- 179.3/375.7 MB 10.4 MB/s eta 0:00:19\n",
      "   ------------------ -------------------- 181.7/375.7 MB 10.4 MB/s eta 0:00:19\n",
      "   ------------------- ------------------- 184.3/375.7 MB 10.4 MB/s eta 0:00:19\n",
      "   ------------------- ------------------- 186.9/375.7 MB 10.4 MB/s eta 0:00:19\n",
      "   ------------------- ------------------- 188.5/375.7 MB 10.4 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 189.5/375.7 MB 10.3 MB/s eta 0:00:19\n",
      "   ------------------- ------------------- 192.2/375.7 MB 10.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------ 194.8/375.7 MB 10.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------ 197.4/375.7 MB 10.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------ 199.8/375.7 MB 10.4 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 202.4/375.7 MB 10.4 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 204.7/375.7 MB 10.4 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 207.4/375.7 MB 10.4 MB/s eta 0:00:17\n",
      "   --------------------- ----------------- 210.0/375.7 MB 10.5 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 212.6/375.7 MB 10.5 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 215.0/375.7 MB 10.5 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 217.6/375.7 MB 10.5 MB/s eta 0:00:16\n",
      "   ---------------------- ---------------- 220.2/375.7 MB 10.5 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 222.6/375.7 MB 10.5 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 224.9/375.7 MB 10.5 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 227.5/375.7 MB 10.6 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 230.2/375.7 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 232.5/375.7 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 234.9/375.7 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 237.2/375.7 MB 10.6 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 239.9/375.7 MB 10.6 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 242.5/375.7 MB 10.6 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 245.1/375.7 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 247.5/375.7 MB 10.7 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 250.1/375.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 252.7/375.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 255.1/375.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 257.7/375.7 MB 10.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 260.0/375.7 MB 10.7 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 262.7/375.7 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 265.3/375.7 MB 10.8 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 267.9/375.7 MB 10.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 270.5/375.7 MB 10.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 272.9/375.7 MB 10.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 275.5/375.7 MB 10.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 277.9/375.7 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 280.2/375.7 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 282.6/375.7 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 285.2/375.7 MB 10.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 287.8/375.7 MB 11.0 MB/s eta 0:00:09\n",
      "   ------------------------------ -------- 290.5/375.7 MB 11.0 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 293.1/375.7 MB 11.0 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 295.4/375.7 MB 11.0 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 298.1/375.7 MB 11.0 MB/s eta 0:00:08\n",
      "   ------------------------------- ------- 300.7/375.7 MB 11.1 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 303.0/375.7 MB 11.1 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 305.7/375.7 MB 11.1 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 308.0/375.7 MB 11.1 MB/s eta 0:00:07\n",
      "   -------------------------------- ------ 310.9/375.7 MB 11.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 313.3/375.7 MB 11.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 315.9/375.7 MB 11.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 318.2/375.7 MB 11.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 320.9/375.7 MB 11.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 323.2/375.7 MB 11.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 325.8/375.7 MB 11.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 328.5/375.7 MB 11.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 330.8/375.7 MB 11.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 333.4/375.7 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 336.1/375.7 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 338.7/375.7 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 341.0/375.7 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 343.7/375.7 MB 11.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 346.3/375.7 MB 11.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 348.9/375.7 MB 11.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 351.5/375.7 MB 11.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 353.6/375.7 MB 11.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 356.3/375.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 358.6/375.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 361.0/375.7 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.6/375.7 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------------  366.2/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  368.8/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  371.2/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.6/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 375.7/375.7 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.71.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Using cached protobuf-5.29.4-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.6/3.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.2 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp39-cp39-win_amd64.whl (292 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, markdown-it-py, markdown, tensorboard, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/25 [libclang]\n",
      "   - --------------------------------------  1/25 [libclang]\n",
      "   --- ------------------------------------  2/25 [flatbuffers]\n",
      "   ------ ---------------------------------  4/25 [werkzeug]\n",
      "   ----------- ----------------------------  7/25 [tensorboard-data-server]\n",
      "  Attempting uninstall: protobuf\n",
      "   ----------- ----------------------------  7/25 [tensorboard-data-server]\n",
      "    Found existing installation: protobuf 6.31.0\n",
      "   ----------- ----------------------------  7/25 [tensorboard-data-server]\n",
      "    Uninstalling protobuf-6.31.0:\n",
      "   ----------- ----------------------------  7/25 [tensorboard-data-server]\n",
      "      Successfully uninstalled protobuf-6.31.0\n",
      "   ----------- ----------------------------  7/25 [tensorboard-data-server]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   -------------- -------------------------  9/25 [optree]\n",
      "   -------------------- ------------------- 13/25 [h5py]\n",
      "   -------------------- ------------------- 13/25 [h5py]\n",
      "   ---------------------- ----------------- 14/25 [grpcio]\n",
      "   ------------------------ --------------- 15/25 [google-pasta]\n",
      "   ------------------------------ --------- 19/25 [markdown-it-py]\n",
      "   -------------------------------- ------- 20/25 [markdown]\n",
      "   --------------------------------- ------ 21/25 [tensorboard]\n",
      "   --------------------------------- ------ 21/25 [tensorboard]\n",
      "   --------------------------------- ------ 21/25 [tensorboard]\n",
      "   --------------------------------- ------ 21/25 [tensorboard]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   ---------------------------------------- 25/25 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac8edd-d4ec-483b-b54b-66aff7a0be30",
   "metadata": {},
   "source": [
    "**Architecture Keras (embedding + tabulaire)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a986e551-6756-4d47-a395-649e94e59333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Entrées\n",
    "input_tab = Input(shape=(X_train.shape[1],), name='tabular_input')\n",
    "input_letters = Input(shape=(1,), name='letters_input')\n",
    "\n",
    "# Embedding des lettres\n",
    "embed = Embedding(input_dim=1000, output_dim=4)(input_letters)  # Adapté au nombre réel d'encodages\n",
    "embed_flat = Flatten()(embed)\n",
    "\n",
    "# Branche tabulaire\n",
    "x = Dense(64, activation='relu')(input_tab)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Fusion et sortie\n",
    "merged = Concatenate()([x, embed_flat])\n",
    "output = Dense(1)(merged)\n",
    "\n",
    "# Modèle\n",
    "nn_model = Model(inputs=[input_tab, input_letters], outputs=output)\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a603e26-fb1e-40bd-a44a-877627335b3b",
   "metadata": {},
   "source": [
    "**Préparation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61a69fc5-bfb0-431f-869e-fec2bfd87870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding des lettres\n",
    "le = LabelEncoder()\n",
    "train_letters_encoded = le.fit_transform(train['letters'])  # ⚠️ colonne : 'lettres' ou 'letters' ?\n",
    "test_letters_encoded = le.transform(test['letters'])\n",
    "\n",
    "# Prédictions LGBM\n",
    "X_train_lgbm = X_train.drop(columns=['letters'], errors='ignore')\n",
    "X_test_lgbm = X_test_prepared.drop(columns=['letters'], errors='ignore')\n",
    "\n",
    "lgbm_train_preds = model.predict(X_train_lgbm)\n",
    "lgbm_test_preds = model.predict(X_test_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a06ef66a-0719-4ee3-9018-61ac032ea967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tab = X_train.drop(columns=['letters'], errors='ignore')\n",
    "X_test_tab = X_test_prepared.drop(columns=['letters'], errors='ignore')\n",
    "\n",
    "X_train_nn = {\n",
    "    'tabular_input': X_train_tab.astype('float32'),\n",
    "    'letters_input': train_letters_encoded.astype('int32')\n",
    "}\n",
    "\n",
    "X_test_nn = {\n",
    "    'tabular_input': X_test_tab.astype('float32'),\n",
    "    'letters_input': test_letters_encoded.astype('int32')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1ab7a-9232-408a-9b7a-e2e199f9d8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e013496-9e96-4c6c-a3ff-880551b6d6ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (51635,) (41308,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m lgbm_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_tab)\n\u001b[1;32m----> 5\u001b[0m residuals \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlgbm_preds\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Split synchronisé\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X_tab_train, X_tab_val, letters_train, letters_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      9\u001b[0m     X_train_tab, letters_enc, residuals, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (51635,) (41308,) "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train['log_price']\n",
    "lgbm_preds = model.predict(X_train_tab)\n",
    "residuals = y - lgbm_preds\n",
    "\n",
    "# Split synchronisé\n",
    "X_tab_train, X_tab_val, letters_train, letters_val, y_train, y_val = train_test_split(\n",
    "    X_train_tab, letters_enc, residuals, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48922e1-39de-4ddc-b132-ec12a8cf3558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ae712f-2911-4745-b4f3-be218cbcf629",
   "metadata": {},
   "source": [
    "**Entraînement du modèle Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7220c6c1-f463-4ab8-b9d9-8c52aa5bf4d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 46471, 41308\n'y' sizes: 41308\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# prédire les erreurs de LGBM\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\kaggle_plates\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:115\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    111\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 46471, 41308\n'y' sizes: 41308\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(\n",
    "    X_train_nn,\n",
    "    residuals,  # prédire les erreurs de LGBM\n",
    "    epochs=40,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164a49b-4b59-4f86-b19e-d870f06181f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63dbf7-7891-4d65-a700-ebaa3d8261de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7080-c349-46f8-8191-6b67c3972e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Prédiction hybride**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4a72-fe50-4cdb-8ae2-569d652381a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_preds = model.predict(X_test)\n",
    "nn_preds = nn_model.predict(X_test_nn).flatten()\n",
    "\n",
    "# Fusion 70% LGBM + 30% NN\n",
    "final_preds = 0.7 * lgbm_preds + 0.3 * nn_preds\n",
    "final_preds = np.expm1(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, np.quantile(final_preds, 0.99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d4b4b-3dd3-4c3d-9ef0-bc11a24f2cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a0fc4-34d2-4d0e-bba3-af090690bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Soumission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c323121-5177-4eee-bd8e-1f693d984119",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID': test['id'], 'Price': final_preds.round()})\n",
    "submission.to_csv(\"submission_hybrid_nn_lgbm.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfd295-4458-48f5-ac69-b759a9074a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6431e6-5ce5-4194-933c-f171a3013a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-kaggle_plates]",
   "language": "python",
   "name": "conda-env-.conda-kaggle_plates-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
